{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DEIT_NST_FULL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZVk+JoKBEbDPBvHveMHeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jing-yu-lim/NST-Content-Image-Reconstruction-with-DEIT-Transformer/blob/main/DEIT_NST_FULL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14Oihn0FzAU"
      },
      "source": [
        "# NST using DEIT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Bycg1gsOiB"
      },
      "source": [
        "# DeiT is built on top of timm. BUT version 0.3.2 does not work with pytorch 1.9; use latest timm\n",
        "!pip install timm==0.4.12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB83-l7aG4Dn"
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "import timm\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqly6RIbfrDr"
      },
      "source": [
        "#import the model and freeze the layers\n",
        "deit=torch.hub.load('facebookresearch/deit:main','deit_base_patch16_224',pretrained=True)\n",
        "\n",
        "for param in deit.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "deit.to(device)\n",
        "deit.eval()\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui54rzXlqlpz"
      },
      "source": [
        "#load image and transform according to DEIT inputs\n",
        "def load_image(url,max_size=400,shape=None,is_url=True):\n",
        "    \n",
        "    if is_url:\n",
        "        image=Image.open(requests.get(url,stream=True).raw)\n",
        "    else:\n",
        "        image=Image.open(url)  \n",
        "\n",
        "    transform=T.Compose([\n",
        "                        T.Resize(256, interpolation=3),\n",
        "                        T.CenterCrop(224),\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(IMAGENET_DEFAULT_MEAN,IMAGENET_DEFAULT_STD),                         \n",
        "                        ])\n",
        "    \n",
        "    if image.mode !='RGB':\n",
        "        image=image.convert('RGB')\n",
        "\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "    return image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40_-C4SFysVv"
      },
      "source": [
        "#if image is not from an url, set is_url=False\n",
        "c_url= 'https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1.00xw:0.669xh;0,0.190xh&resize=1200:*'\n",
        "content_t=load_image(c_url).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_YxAhplXioW"
      },
      "source": [
        "s_url='https://i.pinimg.com/originals/c3/76/47/c37647d3cd724c0dc86a7db7627eaba5.jpg'\n",
        "style_t=load_image(s_url).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jy7QYY9050o"
      },
      "source": [
        "def im_convert(tensor):    \n",
        "    image = tensor.to(\"cpu\").clone().detach()\n",
        "    image = image.numpy().squeeze()\n",
        "    image = image.transpose(1,2,0)\n",
        "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
        "    image = image.clip(0, 1)\n",
        "\n",
        "    return image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro4TPMlCAyfQ"
      },
      "source": [
        "#all the transformer blocks in DEIT\n",
        "for n , p in deit.blocks._modules.items():\n",
        "    print(n,type(p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIPnYzU4wrJb"
      },
      "source": [
        "def get_deit_features(im,model=deit,block_num=None):\n",
        "    block_features=[]\n",
        "    if block_num == None:\n",
        "        block_num=[0,2,4,6,8,10]\n",
        "    hooks=[]\n",
        "\n",
        "    def hook_fn (self, input, output):\n",
        "        block_features.append(output)\n",
        "\n",
        "    for i in block_num:\n",
        "        hooks.append(model.blocks[i].register_forward_hook(hook_fn))\n",
        "           \n",
        "    outputs=model(im)\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "    \n",
        "    return dict(zip(block_num,block_features))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV38Y2qVYeaW"
      },
      "source": [
        "#gram matrix\n",
        "def gram(feature):\n",
        "  feature=feature.squeeze(0)\n",
        "  feature=torch.transpose(feature,1,0)\n",
        "  return torch.matmul(feature,feature.T)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhcdTex4uMps"
      },
      "source": [
        "#specify the block number to retrieve features from deit\n",
        "block_num=[0,1,2,3,4,5,6,7,8,9,10,11]\n",
        "c_features=get_deit_features(content_t,model=deit,block_num=block_num) \n",
        "s_features=get_deit_features(style_t,model=deit,block_num=block_num)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtMkJLipFEJR"
      },
      "source": [
        "#768 is the embedding dimension of vision transformer\n",
        "#196 is because of the number of patches and center crop: 224x224 (img size) /  (16x16) (patch size) = 196 \n",
        "# +1 classification token\n",
        "for n,p in c_features.items():\n",
        "    print(n, p.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNsNbt5c8IVY"
      },
      "source": [
        "#create file directory\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dir = 'pics'\n",
        "if os.path.exists(dir):\n",
        "    shutil.rmtree(dir)\n",
        "os.makedirs(dir)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpT4NdrBB8aq"
      },
      "source": [
        "#initialise generated image with noise\n",
        "gen_image=(torch.rand_like(content_t)).requires_grad_(True).to(device)\n",
        "# gen_image=content_t.clone().requires_grad_(True).to(device)\n",
        "\n",
        "fig,ax = plt.subplots(1,3,figsize=(15,10))\n",
        "ax[0].axis('off')\n",
        "ax[0].imshow(im_convert(content_t))\n",
        "ax[0].set_title('Content Image')\n",
        "\n",
        "ax[1].axis('off')\n",
        "ax[1].imshow(im_convert(gen_image))\n",
        "ax[1].set_title('Generated Image')\n",
        "\n",
        "ax[2].axis('off')\n",
        "ax[2].imshow(im_convert(style_t))\n",
        "ax[2].set_title('Style Image')\n",
        "\n",
        "\n",
        "plt.savefig('/content/pics/NST_before.jpg')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UktVFDz75xT-"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPaK0eP6Ho0r"
      },
      "source": [
        "#specify the weight of each layer\n",
        "content_layer_weights=[1]*12\n",
        "content_layer_weights=dict(zip(block_num,content_layer_weights))\n",
        "\n",
        "style_layer_weights=[1]*12\n",
        "style_layer_weights=dict(zip(block_num,style_layer_weights))\n",
        "\n",
        "\n",
        "overall_content_weight=1e9\n",
        "overall_style_weight=2e9\n",
        "\n",
        "steps = 20000\n",
        "optimizer=torch.optim.Adam([gen_image],lr=0.02)\n",
        "scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.95,verbose=False)\n",
        "lr_epoch=1000"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVKKeEqIT5r8"
      },
      "source": [
        "#to kill processes if cuda memory runs out\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "!/opt/bin/nvidia-smi\n",
        "!ps -aux|grep python\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz8IWjW3Klh4"
      },
      "source": [
        "for i in range(steps):\n",
        "\n",
        "    g_features=get_deit_features(gen_image,block_num=block_num)\n",
        "    total_content_cost=0\n",
        "    \n",
        "    #Use the for loop if using the multilayer content weights \n",
        "    #for layer_num, w in content_layer_weights.items():\n",
        "    layer_content_cost = torch.mean((c_features[0]-g_features[0])**2)\n",
        "    total_content_cost+=1*layer_content_cost\n",
        "\n",
        "    total_style_cost=0\n",
        "    for layer_num, w in style_layer_weights.items():\n",
        "        m,img,dim=g_features[layer_num].size()\n",
        "        style_gram=gram(s_features[layer_num])\n",
        "        gen_gram=gram(g_features[layer_num])\n",
        "        layer_style_cost=torch.mean((style_gram-gen_gram)**2)/(img*dim)\n",
        "        total_style_cost+=w*layer_style_cost\n",
        "\n",
        "\n",
        "    total_cost=overall_content_weight*total_content_cost + overall_style_weight*total_style_cost\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    total_cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%100==0:\n",
        "        print('Total loss:',total_cost)\n",
        "\n",
        "    if i%lr_epoch==0:\n",
        "        scheduler.step() \n",
        "        l_rate=optimizer.param_groups[0]['lr']\n",
        "        print(f'Learning Rate: {l_rate:.7f}')\n",
        "\n",
        "    if i%500==0:\n",
        "        print('Step: ',i+1)\n",
        "        plt.imshow(im_convert(gen_image))\n",
        "        plt.axis('off')\n",
        "        plt.savefig(f'/content/pics/gen_im{i}.jpg')\n",
        "        plt.show()\n",
        "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "        print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBeHg2r5iswU"
      },
      "source": [
        "fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
        "ax1.imshow(im_convert(content_t))\n",
        "ax1.set_title(\"Content-Image\",fontsize = 20)\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(im_convert(gen_image))\n",
        "ax2.set_title(\"Generated-Image\", fontsize = 20)\n",
        "ax2.axis('off')\n",
        "\n",
        "ax3.imshow(im_convert(style_t))\n",
        "ax3.set_title('Style-Image',fontsize=20)\n",
        "ax3.axis('off')\n",
        "\n",
        "plt.savefig('/content/pics/NST_overall.jpg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8vKxL-ZJMLn"
      },
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/NST_pics.zip /content/pics\n",
        "files.download('/content/NST_pics.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fRqZ1jdJfkY"
      },
      "source": [
        "# Content Image Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Za_XXCb65Hz"
      },
      "source": [
        "#create file directory\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "dir = 'c_pics'\n",
        "if os.path.exists(dir):\n",
        "    shutil.rmtree(dir)\n",
        "os.makedirs(dir)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lzbFdi8x94"
      },
      "source": [
        "#retrieve features\n",
        "block_num=[0]\n",
        "c_re_features=get_deit_features(content_t,model=deit,block_num=block_num) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTksuNKC8jGX"
      },
      "source": [
        "#initialise generated image with noise\n",
        "gen_re_image=(torch.rand_like(content_t)).requires_grad_(True).to(device)\n",
        "\n",
        "fig,ax = plt.subplots(1,2,figsize=(15,10))\n",
        "ax[0].axis('off')\n",
        "ax[0].imshow(im_convert(content_t))\n",
        "ax[0].set_title('Content Image')\n",
        "\n",
        "ax[1].axis('off')\n",
        "ax[1].imshow(im_convert(gen_re_image))\n",
        "ax[1].set_title('Generated Image')\n",
        "\n",
        "plt.savefig('/content/pics/content_vs_gen.jpg') #CALL SAVEFIG BEFORE PLT.SHOW\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I76ct6L7M9w"
      },
      "source": [
        "#if using multi layer, specify the weight of each layer\n",
        "content_layer_weights=[1.5]*1\n",
        "content_layer_weights=dict(zip(block_num,content_layer_weights))\n",
        "\n",
        "overall_content_weight=1e4\n",
        "\n",
        "steps = 10000\n",
        "optimizer=torch.optim.Adam([gen_re_image],lr=0.02)\n",
        "scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.95,verbose=False)\n",
        "lr_epoch=1000 #how often to update the LR"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfPfLzjc7Wed"
      },
      "source": [
        "for i in range(steps):\n",
        "\n",
        "    g_re_features=get_deit_features(gen_re_image,block_num=block_num)\n",
        "    total_content_cost=0\n",
        "    for layer_num, w in content_layer_weights.items():\n",
        "        layer_content_cost = torch.mean((c_re_features[layer_num]-g_re_features[layer_num])**2)\n",
        "        total_content_cost += w*layer_content_cost\n",
        "\n",
        "    total_cost=overall_content_weight*total_content_cost\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    total_cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%100==0:\n",
        "        print('Total loss:',total_cost)\n",
        "\n",
        "    if i%lr_epoch==0:\n",
        "        scheduler.step() \n",
        "        l_rate=optimizer.param_groups[0]['lr']\n",
        "        print(f'Learning Rate: {l_rate:.7f}')\n",
        "\n",
        "    if i%100==0:\n",
        "        print('Step: ',i+1)\n",
        "        plt.imshow(im_convert(gen_re_image))\n",
        "        plt.axis('off')\n",
        "        plt.savefig(f'/content/c_pics/gen_im_{i}.jpg')\n",
        "        plt.show()\n",
        "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "        print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx6Rr_mk9AQJ"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "ax1.imshow(im_convert(content_t))\n",
        "ax1.set_title(\"Content-Image\",fontsize = 20)\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(im_convert(gen_re_image))\n",
        "ax2.set_title(\"Generated-Image\", fontsize = 20)\n",
        "ax2.axis('off')\n",
        "\n",
        "plt.savefig('/content/c_pics/content_gen_overall.jpg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6M3rz1Z8Ty2"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/content_regen.zip /content/c_pics\n",
        "\n",
        "files.download('/content/content_regen.zip')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}